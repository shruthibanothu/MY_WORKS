{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMT4W68JVAl0TN+taUBH9Xv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SvvNQTVvGShD"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n"]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/Churn.csv\")"],"metadata":{"id":"6Mm6XaEMGrYj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.Tenure.unique()"],"metadata":{"id":"zP1n8zx-ZaBh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head(5)"],"metadata":{"id":"6iPgFLUsGx5u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["EDA-Exploratory Data Analysis\n"],"metadata":{"id":"rF6Atc2RcJZU"}},{"cell_type":"code","source":["df.shape\n"],"metadata":{"id":"hDBUgPoNGyXA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"iY8hIcV-G0Yp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"id":"hqwsIQ5LG4ou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe()"],"metadata":{"id":"ZzdDvaE_HNt3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.drop([\"RowNumber\",\"CustomerId\",\"Surname\"],axis = 1, inplace = True)"],"metadata":{"id":"yM4Iz3qNQGPE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"fEfQOy-FMb_X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"7cFpJAQfQW2z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cols_features=list(set(df.columns))"],"metadata":{"id":"AOuA2vr8BpcW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cat_feat=['IsActiveMember',\n"," 'NumOfProducts',\n"," 'Geography',\n"," 'Gender',\n"," 'Exited',\n"," 'HasCrCard','Tenure']\n","\n","num_feat=list(set(cols_features)-set(cat_feat))"],"metadata":{"id":"njCWz550Tbro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head(3)"],"metadata":{"id":"rhyJ76BXentW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cat_feat"],"metadata":{"id":"-KBCkj0AV_7h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_feat"],"metadata":{"id":"SjSwA6QvWX3e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in cat_feat:\n","  print(i)\n","  print(df[i].value_counts())\n","  print(df[i].value_counts(normalize=True)*100)\n","  print(df[i].value_counts().plot.bar())\n","  plt.show()\n","  print(\"*\"*50)"],"metadata":{"id":"_a7kOlRyWZUE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","for i in num_feat:\n","  print(i)\n","  sns.boxplot(df[i])\n","  plt.title(f\"BOXPLOT Of: {i}\")\n","  plt.show()\n","  plt.hist(df[i])\n","  plt.title(f\"distribution: {i}\")\n","  plt.show()\n","  print(\"*\"*50)"],"metadata":{"id":"nXSYpmYFYbGo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# bivariate analysis\n","for i in cat_feat:\n","  print(i)\n","  sns.boxplot(x='Exited',y=i,data=df)\n","  plt.show()\n","  print(\"*\"*50)"],"metadata":{"id":"5cU3Z3wLailo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.heatmap(df[num_feat].corr(),annot= True, cmap ='viridis')\n","plt.show()"],"metadata":{"id":"DoE7jkJdc4D-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.pairplot(df[num_feat +[\"Exited\"]],hue='Exited')"],"metadata":{"id":"RMKPBiJyEHql"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Bivarte analysis of categorical datapoints\n","for feat in cat_feat:\n","  # df.groupby(feat)['Exited'].mean()\n","  print(feat)\n","  df.groupby(feat)['Exited'].mean().plot.bar()\n","  plt.show()"],"metadata":{"id":"BG1jlzjAdSfX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# now build the base line model\n"],"metadata":{"id":"nUFnkw-BmyEq"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, classification_report"],"metadata":{"id":"JBwvKX6bex41"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def base_model_0(row):\n","  return 0\n","\n","def base_model(row):\n","  if row['Tenure']<3 and row['IsActiveMember']==0:\n","    return 1 # Churn\n","  else:\n","    return 0 # Not Churn\n","\n","def base_model_2(row):\n","  if row['NumOfProducts']>2 :\n","    return 1\n","  else:\n","    return 0\n","\n","\n","def base_model_3(row):\n","  if (row['IsActiveMember'] == 0 and (row['Age'] > 40 or row['Geography'] == 'Germany')) or (row['NumOfProducts'] > 2):\n","    return 1 # Churn\n","  else:\n","    return 0 # Not Churn\n","\n","def base_model_4(row):\n","  if row['Age']<18:\n","    return 1\n","  else:\n","    return 0\n","\n","df['base_prediction']=df.apply(base_model_3,axis=1)\n","\n","df['base_prediction_0']=df.apply(base_model_0,axis=1)\n","print(classification_report(df['Exited'],df['base_prediction_0']))\n","\n","df['base_prediction']=df.apply(base_model,axis=1)\n","print(classification_report(df['Exited'],df['base_prediction']))\n","\n","df['base_prediction_2']=df.apply(base_model_2, axis=1)\n","print(classification_report(df['Exited'],df['base_prediction_2']))\n","\n","df['base_prediction_3']=df.apply(base_model_3, axis=1)\n","print(classification_report(df['Exited'],df['base_prediction_3']))\n","\n","df['base_prediction_4']=df.apply(base_model_4, axis=1)\n","print(classification_report(df['Exited'],df['base_prediction_4']))\n","\n"],"metadata":{"id":"LPq51y8XEl4A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#machine learning model\n"],"metadata":{"id":"c4GKALKogMVV"}},{"cell_type":"code","source":["df1=cat_feat+num_feat\n","df1"],"metadata":{"id":"rsPciemqiBUT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Geography'].unique()"],"metadata":{"id":"hOR6NY37sw_y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Geography'].isna().sum()"],"metadata":{"id":"ph2Ati2HtFiA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Gender']=df['Gender'].map({'Female':1, 'Male':0}).astype('int')\n","df['Geography']=df['Geography'].map({'France':0, 'Spain':1, 'Germany':2}).astype('int')"],"metadata":{"collapsed":true,"id":"BK282JvOhW7G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[['Geography', 'Gender']].dtypes"],"metadata":{"id":"ZqntexCDtefi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head(2)"],"metadata":{"id":"-7e-Yvnwj9-A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#cat_feat"],"metadata":{"collapsed":true,"id":"lLcXx3PrlcLW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = df.drop(['Exited'],axis=1)\n","\n","y = df[\"Exited\"]"],"metadata":{"id":"p5ZaY0BIeRfE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x.head(3)"],"metadata":{"collapsed":true,"id":"UQmShM7hgT7T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y.shape"],"metadata":{"id":"t9IKVONkhOYE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x.shape"],"metadata":{"id":"P0CLVl_IhO0i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)"],"metadata":{"id":"3ToVD8Bwh4ss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train"],"metadata":{"collapsed":true,"id":"vuw5ppnYnWfD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train"],"metadata":{"id":"7WXZxPA2nfWA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_test"],"metadata":{"collapsed":true,"id":"zw4PtHHNnaBp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test"],"metadata":{"collapsed":true,"id":"s7WWKIKLnhR3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(x_train.shape,x_test.shape, y_train.shape, y_test.shape)"],"metadata":{"id":"dMaTRAOTmwxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Logistic Regression\n","from sklearn.linear_model import LogisticRegression\n","log_reg=LogisticRegression()\n","log_reg.fit(x_train,y_train)"],"metadata":{"id":"I4X0T2LJm6qV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_lr=log_reg.predict(x_test)\n","print(classification_report(y_test,y_pred_lr))"],"metadata":{"id":"atZb8Cw8erDM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Decision tree\n","from sklearn.tree import DecisionTreeClassifier\n","dt=DecisionTreeClassifier(random_state=0)\n","dt.fit(x_train,y_train)"],"metadata":{"id":"O8zk895SnHoC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_dt=dt.predict(x_test)\n","print(classification_report(y_test,y_pred_dt))"],"metadata":{"id":"AAVKBUTlezmi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["DL- Deep Learning Model\n"],"metadata":{"id":"5GPQosxxccED"}},{"cell_type":"code","source":["#!pip install keras"],"metadata":{"collapsed":true,"id":"y98AI2iHe8cs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install pydot\n","# !pip install tensorflow"],"metadata":{"collapsed":true,"id":"jKaQHrUUhyFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Imports\n","from keras.models import Sequential\n","from keras.layers import Dense, Input\n","import keras as keras\n","from keras import optimizers\n","from keras import metrics\n"],"metadata":{"id":"OoWulD9Fn6l1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Standardization of data\n","from sklearn.preprocessing import StandardScaler\n","sc=StandardScaler()\n","X_train=sc.fit_transform(x_train)\n","X_test=sc.transform(x_test)"],"metadata":{"id":"PXa11UDcn6we"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classifier = Sequential()\n","classifier.add(Dense(10,activation='relu',input_dim=X_train.shape[1])) # Hidden Layer-1\n","classifier.add(Dense(7,activation='relu'))\n","# classifier.add(Dense(32,activation='relu'))\n","# classifier.add(Dense(32,activation='relu'))\n","classifier.add(Dense(1,activation='sigmoid')) # Output Layer\n","classifier.summary()"],"metadata":{"id":"VGiOIW2ouk56"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Compile\n","#Compile\n","classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n","\n","#training\n","history=classifier.fit(X_train,y_train,batch_size=32,epochs=10, validation_data=(X_test,y_test))"],"metadata":{"id":"0VJS2fwNuqmd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["keras.utils.plot_model(classifier,\"my_first_model.png\", show_shapes= True, show_layer_names= True)"],"metadata":{"id":"HL8xbvHNg0nG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#List all data in history\n","print(history.history.keys())\n","\n","#Plot\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","\n","#Plot\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"metadata":{"id":"Hf17phc2uz0N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.layers import Input"],"metadata":{"id":"587WDj_-saQP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modelALT=Sequential([\n","    Dense(5, activation=\"relu\", name=\"layer1\",input_dim=x_train.shape[1]),\n","    Dense(1,activation=\"sigmoid\", name= \"layer2\")\n","])\n","modelALT.summary()\n","\n","modelALT.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])\n","modelALT.fit(x_train,y_train, epochs=10, validation_data=(x_test,y_test))"],"metadata":{"id":"EByWJHpzkHdk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modelALT = Sequential([\n","    Input(shape=(15,)),          # â† matches x_train features\n","    Dense(8, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","modelALT.compile(\n","    optimizer='SGD',\n","    loss='binary_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","modelALT.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"],"metadata":{"id":"RwHzwddKjQTM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Predictions\n","y_pred_dl=classifier.predict(X_test)"],"metadata":{"id":"zhJ1xP9du-xq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ROC-AUC Curve\n","from sklearn.metrics import roc_curve, auc\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred_dl)\n","roc_auc = auc(fpr, tpr)\n","print(roc_auc)\n","\n","# Plot\n","plt.figure()\n","plt.plot(fpr,tpr, label=f\"AUC = {roc_auc}\")\n","plt.plot([0,1],[0,1],\"r--\", label=\"Random Guess\")\n","plt.show()"],"metadata":{"id":"KWJiV19XvCWh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","y_pred_dl1=[]\n","for i in y_pred_dl:\n","  if i>0.6:\n","    y_pred_dl1.append(1)\n","  else:\n","    y_pred_dl1.append(0)\n","\n","print(classification_report(y_test,y_pred_dl1))"],"metadata":{"id":"quPw9fZxvIQ5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Keras Functional API\n","https://keras.io/api/models/\n"],"metadata":{"id":"X80Wob7doxIZ"}},{"cell_type":"code","source":["input = keras.Input(shape=(x_train.shape[1],))\n","hidn=Dense(5,activation='relu')(input)\n","output=Dense(1,activation='sigmoid')(hidn)\n","model=keras.Model(inputs=input, outputs=output, name=\"churn_model\")\n","model.summary()"],"metadata":{"id":"8PyBzjAxoO0t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(x_train,y_train,epochs=10, validation_data=(x_test, y_test))"],"metadata":{"id":"JE_RLZKfpmjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"R5pBTZNpzgpV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"04722c8a-2c92-40be-b9d7-a083f4811fc0"},"outputs":[],"source":["# prompt: Create a ANN network to solve this problem and achieve better accuracy than decision tree used here\n","\n","# Scale the numerical features\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","x_train = scaler.fit_transform(x_train)\n","x_test = scaler.transform(x_test)\n","\n","# Build the ANN model\n","model = Sequential()\n","model.add(Dense(5, activation='relu', input_dim=15))\n","# model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(x_train, y_train, epochs=10,  validation_data=(x_test, y_test))\n","\n","# Evaluate the model\n","_, accuracy = model.evaluate(x_test, y_test)\n","print('Accuracy: {}'.format(accuracy))\n"]},{"cell_type":"code","source":[],"metadata":{"id":"7kkyiaVoz_dn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Predictions\n","y_pred_dl=model.predict(x_test)\n","\n","#ROC-AUC Curve\n","from sklearn.metrics import roc_curve, auc\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred_dl)\n","roc_auc = auc(fpr, tpr)\n","print(roc_auc)\n","\n","# Plot\n","plt.figure()\n","plt.plot(fpr,tpr, label=f\"AUC = {roc_auc}\")\n","plt.plot([0,1],[0,1],\"r--\", label=\"Random Guess\")\n","plt.show()\n","\n","\n","y_pred_dl1=[]\n","for i in y_pred_dl:\n","  if i>0.6:\n","    y_pred_dl1.append(1)\n","  else:\n","    y_pred_dl1.append(0)\n","\n","print(classification_report(y_test,y_pred_dl1))"],"metadata":{"id":"FQ3i-_OvqBnL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x.columns"],"metadata":{"id":"BKTOGt6EzFPE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a ANN network to solve this problem and achieve better accuracy than decision tree used here\n","\n","# Scale the numerical features\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","x_train = scaler.fit_transform(x_train)\n","x_test = scaler.transform(x_test)\n","\n","# Build the ANN model\n","# Build the ANN model\n","model = Sequential()\n","\n","model.add(Dense(64, activation='relu', input_dim=15))\n","#Dropout\n","from keras import layers\n","\n","model.add(layers.Dropout(0.5))\n","\n","model.add(Dense(32, activation='relu'))\n","#Dropout\n","model.add(layers.Dropout(0.5))\n","\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Customize your optimizer\n","from keras.optimizers import Adam\n","custom_optimizer = Adam(learning_rate=0.9)\n","\n","# Compile the model\n","model.compile(optimizer=custom_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Add earlyStopping Callback\n","from keras.callbacks import EarlyStopping\n","early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n","\n","# Train the model\n","history=model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_test, y_test),callbacks=[early_stopping])\n","\n","# Evaluate the model\n","_, accuracy = model.evaluate(x_test, y_test)\n","print('Accuracy: {}'.format(accuracy))\n","\n","# list all data in history\n","print(history.history.keys())\n","# summarize history for accuracy\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"metadata":{"id":"yqSmsOYsvHWE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a ANN network to solve this problem and achieve better accuracy than decision tree used here\n","\n","# Build the ANN model\n","model = Sequential()\n","\n","# Correct input_dim to match the number of features in X_train (which is 15)\n","model.add(Dense(64, activation='relu', input_dim=15))\n","#Dropout\n","from keras import layers\n","\n","model.add(layers.Dropout(0.5))\n","\n","model.add(Dense(32, activation='relu'))\n","#Dropout\n","model.add(layers.Dropout(0.5))\n","\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Customize your optimizer\n","from keras.optimizers import Adam\n","custom_optimizer = Adam(learning_rate=0.9)\n","\n","\n","\n","# Compile the model\n","model.compile(optimizer=custom_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Add earlyStopping Callback\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n","lr_scheduler = LearningRateScheduler(lambda epoch: 0.001 * 0.9 ** epoch)\n","\n","# Train the model\n","history=model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test),callbacks=[early_stopping,lr_scheduler])\n","\n","# Evaluate the model\n","_, accuracy = model.evaluate(X_test, y_test)\n","print('Accuracy: {}'.format(accuracy))\n","\n","# list all data in history\n","print(history.history.keys())\n","# summarize history for accuracy\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"metadata":{"id":"5AT9m22ku3zx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epoch=10\n","0.001 * 0.9 ** epoch"],"metadata":{"id":"cq4TmvKHu73t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# track LR\n","plt.plot(history.history['learning_rate'])\n","plt.title('Learning Rate')\n","plt.ylabel('learning rate')\n","plt.xlabel('epoch')\n","plt.show()"],"metadata":{"id":"earhjfl8u8z2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a ANN network to solve this problem and achieve better accuracy than decision tree used here\n","\n","# Scale the numerical features\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","x_train = scaler.fit_transform(x_train)\n","x_test = scaler.transform(x_test)\n","\n","# Build the ANN model\n","# Build the ANN model\n","model = Sequential()\n","\n","model.add(Dense(64, activation='relu', input_dim=15))\n","#Dropout\n","model.add(layers.Dropout(0.5))\n","\n","model.add(Dense(32, activation='relu'))\n","#Dropout\n","model.add(layers.Dropout(0.5))\n","\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Customize your optimizer\n","from keras.optimizers import Adam\n","custom_optimizer = Adam(learning_rate=0.9)\n","\n","\n","\n","# Compile the model\n","model.compile(optimizer=custom_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Add earlyStopping Callback\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n","lr_scheduler = LearningRateScheduler(lambda epoch: 0.001 * 0.9 ** epoch)\n","#Tensorboard\n","from keras.callbacks import TensorBoard\n","tensorboard = TensorBoard(log_dir='/content/sample_data/model_logs', histogram_freq=0, write_graph=True, write_images=True)\n","\n","# Train the model\n","history=model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test),callbacks=[early_stopping,lr_scheduler,tensorboard])\n","\n","# Evaluate the model\n","_, accuracy = model.evaluate(X_test, y_test)\n","print('Accuracy: {}'.format(accuracy))\n","\n","# list all data in history\n","print(history.history.keys())\n","# summarize history for accuracy\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n"],"metadata":{"id":"w-AaHKMKqSXW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VUctFrwF20uv"},"execution_count":null,"outputs":[]}]}
